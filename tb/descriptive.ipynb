{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data with UTF-8 encoding for Chinese text\n",
    "file_path = '/home/disk1/red_disk1/zhiyi/zhiyi_data/tb_style_sale_202311_202410.csv'\n",
    "data = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Remove duplicate rows\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Verify removal of duplicates\n",
    "data.info()\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "new_file_path = '/home/disk1/red_disk1/zhiyi/zhiyi_data/tb_style_post_cleaned.csv'\n",
    "data.to_csv(new_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Duplicates removed and cleaned data saved to a new CSV file successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 30547374\n",
      "Distinct rows: 22511888\n",
      "Distinct union_id values: 5530173\n",
      "Distinct style_new values: 3687\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data with UTF-8 encoding for Chinese text\n",
    "file_path = '/home/disk1/red_disk1/zhiyi/zhiyi_data/tb_style_post_cleaned.csv'\n",
    "data = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Count total rows in the dataset\n",
    "total_rows_count = data.shape[0]\n",
    "\n",
    "# Display the result\n",
    "print(\"Total rows:\", total_rows_count)\n",
    "\n",
    "# Count distinct rows by considering all columns (to ensure row uniqueness)\n",
    "distinct_rows_count = data.drop_duplicates().shape[0]\n",
    "\n",
    "# Count distinct values in the 'union_id' column\n",
    "distinct_union_id_count = data['union_id'].nunique()\n",
    "\n",
    "# Count distinct values in the 'item_id' column\n",
    "distinct_item_id_count = data['item_id'].nunique()\n",
    "\n",
    "# Display the results\n",
    "print(\"Distinct rows:\", distinct_rows_count)\n",
    "print(\"Distinct union_id values:\", distinct_union_id_count)\n",
    "print(\"Distinct item_id values:\", distinct_item_id_count)\n",
    "\n",
    "# Count distinct values in the 'style_new' column\n",
    "distinct_style_new_count = data['style_new'].nunique()\n",
    "\n",
    "# Display the result\n",
    "print(\"Distinct style_new values:\", distinct_style_new_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check styles\n",
    "1. Clusters the data by style_new.\n",
    "2. Counts the unique union_id and item_id values for each style.\n",
    "3. Sorts the styles by the count of item_id and selects the top 10 styles.\n",
    "4. Visualizes the results in a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column 'note_id' does not exist!\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.unicode_minus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# Ensure minus signs display correctly\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Group by 'style_new' and count unique 'union_id' and 'note_id' for each style\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m style_counts \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstyle_new\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43munique_union_id_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munion_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnunique\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnote_id_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnote_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Sort by 'note_id_count' to get the top 20 styles\u001b[39;00m\n\u001b[1;32m     19\u001b[0m top_10_styles \u001b[38;5;241m=\u001b[39m style_counts\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnote_id_count\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/groupby/generic.py:945\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    942\u001b[0m relabeling, func, columns, order \u001b[38;5;241m=\u001b[39m reconstruct_func(func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    943\u001b[0m func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[0;32m--> 945\u001b[0m result, how \u001b[38;5;241m=\u001b[39m \u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/aggregation.py:582\u001b[0m, in \u001b[0;36maggregate\u001b[0;34m(obj, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_dict_like(arg):\n\u001b[1;32m    581\u001b[0m     arg \u001b[38;5;241m=\u001b[39m cast(AggFuncTypeDict, arg)\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_axis\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(arg):\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;66;03m# we require a list, but not an 'str'\u001b[39;00m\n\u001b[1;32m    585\u001b[0m     arg \u001b[38;5;241m=\u001b[39m cast(List[AggFuncTypeBase], arg)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/aggregation.py:746\u001b[0m, in \u001b[0;36magg_dict_like\u001b[0;34m(obj, arg, _axis)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m SpecificationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnested renamer is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    744\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(selected_obj, ABCDataFrame) \u001b[38;5;129;01mand\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m selected_obj\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m    745\u001b[0m         ):\n\u001b[0;32m--> 746\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    748\u001b[0m     arg \u001b[38;5;241m=\u001b[39m new_arg\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;66;03m# deprecation of renaming keys\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;66;03m# GH 15931\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Column 'note_id' does not exist!\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Set up the font properties for Chinese text\n",
    "chinese_font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'\n",
    "chinese_font = FontProperties(fname=chinese_font_path)\n",
    "mpl.rcParams['font.sans-serif'] = [chinese_font_path]  # Set default font for matplotlib\n",
    "mpl.rcParams['axes.unicode_minus'] = False  # Ensure minus signs display correctly\n",
    "\n",
    "# Group by 'style_new' and count unique 'union_id' and 'item_id' for each style\n",
    "style_counts = data.groupby('style_new').agg(\n",
    "    unique_union_id_count=('union_id', 'nunique'),\n",
    "    item_id_count=('item_id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Sort by 'item_id_count' to get the top 20 styles\n",
    "top_10_styles = style_counts.sort_values(by='item_id_count', ascending=False).head(20)\n",
    "\n",
    "# Plotting the top 20 styles\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(top_10_styles['style_new'], top_10_styles['item_id_count'], label='item Count')\n",
    "ax.plot(top_10_styles['style_new'], top_10_styles['unique_union_id_count'], color='orange', marker='o', label='Union ID Count')\n",
    "\n",
    "# Add labels and legend with Chinese font support\n",
    "ax.set_xlabel('风格', fontproperties=chinese_font)  # 'Style' in Chinese\n",
    "ax.set_ylabel('计数', fontproperties=chinese_font)  # 'Count' in Chinese\n",
    "ax.set_title('按Item ID计数的前20风格', fontproperties=chinese_font)  # 'Top 20 Styles by item ID Count' in Chinese\n",
    "ax.legend(prop=chinese_font)\n",
    "plt.xticks(rotation=45, fontproperties=chinese_font)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results in a table format\n",
    "top_10_styles.columns = ['Style', 'Union ID Count', 'Note ID Count']\n",
    "print(top_10_styles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
